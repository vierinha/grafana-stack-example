logging {
    level  = "error"
}

otelcol.receiver.otlp "otlp_receiver" {
  http {
    endpoint = "0.0.0.0:4318"
  }
  grpc {
    endpoint = "0.0.0.0:4317"
  }

  output {
    metrics = [otelcol.processor.batch.otlp_processor.input]
    logs    = [otelcol.processor.batch.otlp_processor.input]
    traces  = [otelcol.processor.batch.otlp_processor.input]
  }
}

otelcol.processor.batch "otlp_processor" {
  output {
    metrics = [otelcol.exporter.otlphttp.otlp_exporter.input]
    logs    = [otelcol.exporter.otlphttp.otlp_exporter.input]
    traces  = [otelcol.exporter.otlphttp.otlp_exporter.input]
  }
}

otelcol.auth.basic "basic_auth" {
  username = "default"
  password = "default"
}

otelcol.exporter.otlphttp "otlp_exporter" {
  client {
    endpoint = "http://nginx:8080/otlp"
    auth     = otelcol.auth.basic.basic_auth.handler
  }
}

prometheus.scrape "scraper_grafana" {
    job_name        = "grafana"
    targets         = [{"__address__"   = "grafana:3000"}]
    forward_to      = [prometheus.remote_write.prometheus_exporter.receiver]
    scrape_interval = "15s"
    scrape_timeout = "15s"
    metrics_path    = "/metrics"
}

prometheus.scrape "scraper_loki" {
    job_name        = "loki"
    targets         = [{"__address__"   = "loki:3100"}]
    forward_to      = [prometheus.remote_write.prometheus_exporter.receiver]
    scrape_interval = "15s"
    scrape_timeout = "15s"
    metrics_path    = "/metrics"
}

prometheus.scrape "scraper_mimir" {
    job_name        = "mimir"
    targets         = [{"__address__"   = "mimir:9009"}]
    forward_to      = [prometheus.remote_write.prometheus_exporter.receiver]
    scrape_interval = "15s"
    scrape_timeout = "15s"
    metrics_path    = "/metrics"
}

prometheus.scrape "scraper_tempo" {
    job_name        = "tempo"
    targets         = [{"__address__"   = "tempo:3200"}]
    forward_to      = [prometheus.remote_write.prometheus_exporter.receiver]
    scrape_interval = "15s"
    scrape_timeout = "15s"
    metrics_path    = "/metrics"
}

prometheus.scrape "scraper_alloy" {
    job_name        = "alloy"
    targets         = [{"__address__"   = "alloy:12345"}]
    forward_to      = [prometheus.remote_write.prometheus_exporter.receiver]
    scrape_interval = "15s"
    scrape_timeout = "15s"
    metrics_path    = "/metrics"
}

prometheus.remote_write "prometheus_exporter" {
  endpoint {
    url = "http://nginx:8080/prometheus/api/v1/push"
    basic_auth {
      username = "default"
      password = "default"
    }
  }
}

discovery.docker "containerlogs" {
	host             = "unix:///var/run/docker.sock"
	refresh_interval = "2s"
}

loki.process "containerlogs" {
	forward_to = [loki.write.loki_exporter.receiver]

	stage.static_labels {
		values = {
			host = "HOSTNAME",
			job  = "docker.sock",
		}
	}
}

discovery.relabel "containerlogs" {
	targets = []

	rule {
		source_labels = ["__meta_docker_container_name"]
		regex         = "/(.*)"
		target_label  = "container"
	}
}

loki.source.docker "containerlogs" {
	host             = "unix:///var/run/docker.sock"
	targets          = discovery.docker.containerlogs.targets
	forward_to       = [loki.process.containerlogs.receiver]
	relabel_rules    = discovery.relabel.containerlogs.rules
	refresh_interval = "2s"
}

loki.write "loki_exporter" {
  endpoint {
    url       = "http://nginx:8080/loki/api/v1/push"
    basic_auth {
      username = "default"
      password = "default"
    }
  }
}